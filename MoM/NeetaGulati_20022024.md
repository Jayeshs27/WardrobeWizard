<span id="anchor"></span>Minutes of Meeting

- **Tasks** (T) - has an Owner and a deadline

- **Decisions** (D)

- **Information** (I) - everything else of interest

- **Date:** 20-02-24

- **Time:** 6:00 PM

- **Topic:** Project Development, Product Deployment, Machine Learning Implementation & Optimization

- **Goal:** To discuss  solutions for enhancing user retention, optimizing system architecture, using LLMs for developing V1 of the product, and addressing concerns related to hosting and latency of machine learning models on the cloud. 

- **Attendees:**
  - Team: Shaunak Biswas, Harpreet Singh, Jayesh Sutar,  Raveesh Vyas
  - Client: Dr. Neeta Gulati
  - Guest: Mr. Apurv P

| Type | Description | Owner | Deadline |
|------|-------------|-------|----------|
| I    | Mr. Apurv has identified a concerning user retention issue, proposing the introduction of compelling content for new users to enhance their experience and emphasize the platform's value, ensuring greater engagement and retention. | - | - |
| I    | Mr. Apurv emphasized leveraging existing LLMs and SMLMs with minor adjustments instead of developing a model from the ground up, highlighting the advantage of expediting development for V1 and transitioning to SLMs later for enhanced performance. | - | - |
| I    | Mr. Apurv suggested decoupling different parts of the system, approving our use of FastAPI to achieve this, which allows for the replacement of machine learning models bringing flexibility within the system architecture.| - | - |
| I    | When questioned about hosting an ML model on the cloud requiring weekly runs, Mr. Apurv again suggested for a decoupling approach, emphasizing the separation of concerns.| - | - |
| I    | He recommended exploring options such as GitHub Copilot and Google Gemini for potential solutions.| - | - |
| I    | In response to a question regarding the latency of models on the cloud, Mr. Apurv asserted that modern internet speeds would adequately address concerns about latency.| - | - |

- **Next Meeting:** ```24/02/2024``` (tentative)
